{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-917ebc1dda03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda, concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from matplotlib.colors import LogNorm\n",
    "import pylab as py\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]\n",
    "matplotlib.rc('text',usetex=True)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from matplotlib.colors import LogNorm\n",
    "import pylab as py\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--choose working directory to generate samples\n",
    "wdir = 'simul'\n",
    "\n",
    "#--choose number of samples\n",
    "N = 100\n",
    "\n",
    "print('Generating new priors for %s'%wdir)\n",
    "\n",
    "load_config('%s/input.py'%wdir)\n",
    "istep=core.get_istep()\n",
    "\n",
    "cluster,colors,nc,cluster_order = classifier.get_clusters(wdir,istep,kc) \n",
    "best_cluster=cluster_order[0]\n",
    "  \n",
    "#--get data\n",
    "replicas=core.get_replicas(wdir)\n",
    "step=conf['steps'][istep]\n",
    "samples=[]\n",
    "for i in range(len(replicas)):\n",
    "\n",
    "    if cluster[i]!=best_cluster: continue\n",
    "    replica=replicas[i]\n",
    "    order=replica['order'][istep]\n",
    "    params=replica['params'][istep]\n",
    "    samples.append(params)\n",
    "\n",
    "samples=np.array(samples)\n",
    "\n",
    "#--normalize samples\n",
    "samples_mean = np.mean(samples, axis = 0)\n",
    "samples_std  = np.std(samples, axis = 0)\n",
    "norm_samples = (samples - samples_mean)/samples_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 199)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGAN():\n",
    "    def __init__(self):\n",
    "        self.img_shape = (norm_samples.shape[1],)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.000001, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        # (!!!) Optimize w.r.t. MSE loss instead of crossentropy\n",
    "        self.combined.compile(loss='mse', optimizer=optimizer)\n",
    "              \n",
    "    def build_generator(self):\n",
    "        visible = Input(shape=(100,))\n",
    "        hidden1 = Dense(256,  input_dim=self.latent_dim)(visible)\n",
    "        LR = LeakyReLU(alpha=0.2)(hidden1)\n",
    "        LR = BatchNormalization(momentum=0.8)(LR)\n",
    "        hidden2 = Dense(512)(LR)\n",
    "        LR = LeakyReLU(alpha=0.2)(hidden2)\n",
    "        LR = BatchNormalization(momentum=0.8)(LR)\n",
    "        hidden3 = Dense(1024)(LR)\n",
    "        LR = LeakyReLU(alpha=0.2)(hidden3)\n",
    "        LR = BatchNormalization(momentum=0.8)(LR)\n",
    "        output = Dense(norm_samples.shape[1])(LR)\n",
    "        #features = Lambda(self.feature_mul)(output)\n",
    "        #outputmerge = concatenate([output, features])\n",
    "        #generator = Model(inputs=visible, outputs=[outputmerge])\n",
    "        generator = Model(inputs=visible, outputs=[output])\n",
    "        generator.summary()\n",
    "        img = generator(visible)\n",
    "        return Model(visible, img)\n",
    "\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_shape=self.img_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # after the model converges I reduce the drop rate to 0.001\n",
    "        model.add(Dropout(0.001))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.001))\n",
    "        # (!!!) No softmax\n",
    "        model.add(Dense(1))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "                  \n",
    "        X_train = norm_samples\n",
    "        print(X_train.shape)\n",
    "\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "#         self.generator.load_weights('ls_generator.h5')\n",
    "#         self.discriminator.load_weights('ls_discriminator.h5')\n",
    "        \n",
    "        dloss=[]\n",
    "        gloss=[]\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            #print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            #loss_gen.append(g_loss[0])\n",
    "            #loss_dis.append(d_loss[0])\n",
    "            \n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            dloss=np.append(dloss,d_loss[0])\n",
    "            gloss=np.append(gloss,g_loss)\n",
    "            if epoch % sample_interval == 0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                self.generator.save_weights('generator_weights.h5')\n",
    "                self.discriminator.save_weights('discrimiantor_weights.h5')\n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 512)               102400    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 233,985\n",
      "Trainable params: 233,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 199)               203975    \n",
      "=================================================================\n",
      "Total params: 893,895\n",
      "Trainable params: 890,311\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = LSGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 199)\n",
      "0 [D loss: 0.662631, acc.: 50.00%] [G loss: 0.967682]\n",
      "10 [D loss: 1.015861, acc.: 35.00%] [G loss: 0.765207]\n",
      "20 [D loss: 0.909829, acc.: 40.00%] [G loss: 1.089484]\n",
      "30 [D loss: 0.904638, acc.: 45.00%] [G loss: 0.935809]\n",
      "40 [D loss: 0.326910, acc.: 65.00%] [G loss: 1.081763]\n",
      "50 [D loss: 1.015040, acc.: 25.00%] [G loss: 1.319420]\n",
      "60 [D loss: 0.743823, acc.: 40.00%] [G loss: 1.149999]\n",
      "70 [D loss: 0.869530, acc.: 40.00%] [G loss: 1.011420]\n",
      "80 [D loss: 1.005724, acc.: 35.00%] [G loss: 0.745978]\n",
      "90 [D loss: 0.639236, acc.: 50.00%] [G loss: 1.083322]\n",
      "100 [D loss: 0.850170, acc.: 50.00%] [G loss: 1.020738]\n",
      "110 [D loss: 0.649844, acc.: 40.00%] [G loss: 0.653811]\n",
      "120 [D loss: 0.534480, acc.: 60.00%] [G loss: 1.037205]\n",
      "130 [D loss: 0.750538, acc.: 45.00%] [G loss: 0.919365]\n",
      "140 [D loss: 0.785519, acc.: 50.00%] [G loss: 1.229224]\n",
      "150 [D loss: 0.497212, acc.: 45.00%] [G loss: 1.000675]\n",
      "160 [D loss: 0.824176, acc.: 35.00%] [G loss: 0.546715]\n",
      "170 [D loss: 0.427022, acc.: 45.00%] [G loss: 1.001580]\n",
      "180 [D loss: 0.881515, acc.: 30.00%] [G loss: 0.859940]\n",
      "190 [D loss: 0.841179, acc.: 30.00%] [G loss: 0.520577]\n",
      "200 [D loss: 0.931606, acc.: 50.00%] [G loss: 0.738480]\n",
      "210 [D loss: 0.727426, acc.: 50.00%] [G loss: 1.109899]\n",
      "220 [D loss: 0.864274, acc.: 45.00%] [G loss: 0.594769]\n",
      "230 [D loss: 0.606973, acc.: 55.00%] [G loss: 0.488643]\n",
      "240 [D loss: 1.194743, acc.: 15.00%] [G loss: 0.675544]\n",
      "250 [D loss: 0.578190, acc.: 50.00%] [G loss: 0.814674]\n",
      "260 [D loss: 0.911553, acc.: 45.00%] [G loss: 0.813876]\n",
      "270 [D loss: 0.686388, acc.: 40.00%] [G loss: 0.641872]\n",
      "280 [D loss: 0.609185, acc.: 55.00%] [G loss: 0.634602]\n",
      "290 [D loss: 0.817072, acc.: 40.00%] [G loss: 0.761890]\n",
      "300 [D loss: 0.470124, acc.: 55.00%] [G loss: 1.010229]\n",
      "310 [D loss: 0.470540, acc.: 55.00%] [G loss: 0.737266]\n",
      "320 [D loss: 0.630447, acc.: 50.00%] [G loss: 0.634853]\n",
      "330 [D loss: 0.828367, acc.: 45.00%] [G loss: 0.982485]\n",
      "340 [D loss: 0.628633, acc.: 50.00%] [G loss: 0.890766]\n",
      "350 [D loss: 0.543311, acc.: 50.00%] [G loss: 0.540731]\n",
      "360 [D loss: 0.333577, acc.: 65.00%] [G loss: 0.635991]\n",
      "370 [D loss: 0.503445, acc.: 50.00%] [G loss: 0.531353]\n",
      "380 [D loss: 0.605055, acc.: 40.00%] [G loss: 0.492305]\n",
      "390 [D loss: 0.810330, acc.: 40.00%] [G loss: 0.827856]\n",
      "400 [D loss: 0.580911, acc.: 35.00%] [G loss: 0.380765]\n",
      "410 [D loss: 0.748849, acc.: 45.00%] [G loss: 0.654246]\n",
      "420 [D loss: 0.464663, acc.: 60.00%] [G loss: 0.698378]\n",
      "430 [D loss: 0.823041, acc.: 35.00%] [G loss: 0.650217]\n",
      "440 [D loss: 0.635449, acc.: 40.00%] [G loss: 0.605760]\n",
      "450 [D loss: 0.529903, acc.: 45.00%] [G loss: 0.365431]\n",
      "460 [D loss: 0.450355, acc.: 50.00%] [G loss: 0.670966]\n",
      "470 [D loss: 0.408856, acc.: 50.00%] [G loss: 0.584951]\n",
      "480 [D loss: 1.208424, acc.: 20.00%] [G loss: 0.248212]\n",
      "490 [D loss: 0.465809, acc.: 30.00%] [G loss: 0.612609]\n",
      "500 [D loss: 0.571552, acc.: 55.00%] [G loss: 0.725242]\n",
      "510 [D loss: 0.664848, acc.: 40.00%] [G loss: 0.482091]\n",
      "520 [D loss: 0.693099, acc.: 60.00%] [G loss: 0.745168]\n",
      "530 [D loss: 0.429169, acc.: 55.00%] [G loss: 0.365859]\n",
      "540 [D loss: 0.476223, acc.: 40.00%] [G loss: 0.785603]\n",
      "550 [D loss: 0.722293, acc.: 25.00%] [G loss: 0.513535]\n",
      "560 [D loss: 0.931713, acc.: 35.00%] [G loss: 0.416802]\n",
      "570 [D loss: 0.793319, acc.: 40.00%] [G loss: 0.486112]\n",
      "580 [D loss: 0.532886, acc.: 45.00%] [G loss: 0.933596]\n",
      "590 [D loss: 0.729350, acc.: 20.00%] [G loss: 0.401594]\n",
      "600 [D loss: 0.485866, acc.: 55.00%] [G loss: 0.693342]\n",
      "610 [D loss: 0.843399, acc.: 30.00%] [G loss: 0.437229]\n",
      "620 [D loss: 0.871227, acc.: 55.00%] [G loss: 0.452284]\n",
      "630 [D loss: 0.400858, acc.: 65.00%] [G loss: 0.860161]\n",
      "640 [D loss: 0.502832, acc.: 50.00%] [G loss: 0.575367]\n",
      "650 [D loss: 1.021430, acc.: 30.00%] [G loss: 0.596638]\n",
      "660 [D loss: 0.339123, acc.: 60.00%] [G loss: 0.338216]\n",
      "670 [D loss: 0.588870, acc.: 35.00%] [G loss: 0.613219]\n",
      "680 [D loss: 0.639522, acc.: 30.00%] [G loss: 0.553990]\n",
      "690 [D loss: 1.073531, acc.: 35.00%] [G loss: 0.328117]\n",
      "700 [D loss: 0.513094, acc.: 60.00%] [G loss: 0.691068]\n",
      "710 [D loss: 0.576789, acc.: 45.00%] [G loss: 1.081239]\n",
      "720 [D loss: 0.565078, acc.: 40.00%] [G loss: 0.531145]\n",
      "730 [D loss: 0.702657, acc.: 55.00%] [G loss: 0.591387]\n",
      "740 [D loss: 0.365197, acc.: 55.00%] [G loss: 0.566787]\n",
      "750 [D loss: 0.756336, acc.: 40.00%] [G loss: 0.369781]\n",
      "760 [D loss: 0.227551, acc.: 70.00%] [G loss: 0.647395]\n",
      "770 [D loss: 0.248641, acc.: 70.00%] [G loss: 0.668131]\n",
      "780 [D loss: 0.656929, acc.: 40.00%] [G loss: 0.524584]\n",
      "790 [D loss: 0.411825, acc.: 50.00%] [G loss: 0.671062]\n",
      "800 [D loss: 0.621513, acc.: 55.00%] [G loss: 0.510481]\n",
      "810 [D loss: 0.490202, acc.: 35.00%] [G loss: 0.586151]\n",
      "820 [D loss: 0.594878, acc.: 35.00%] [G loss: 0.631314]\n",
      "830 [D loss: 0.423701, acc.: 55.00%] [G loss: 0.700282]\n",
      "840 [D loss: 0.721447, acc.: 15.00%] [G loss: 0.459369]\n",
      "850 [D loss: 0.644349, acc.: 50.00%] [G loss: 0.569266]\n",
      "860 [D loss: 0.737803, acc.: 50.00%] [G loss: 0.614845]\n",
      "870 [D loss: 0.534367, acc.: 45.00%] [G loss: 0.839204]\n",
      "880 [D loss: 0.487125, acc.: 30.00%] [G loss: 0.766668]\n",
      "890 [D loss: 0.432677, acc.: 45.00%] [G loss: 0.537129]\n",
      "900 [D loss: 0.400592, acc.: 60.00%] [G loss: 0.756779]\n",
      "910 [D loss: 0.742596, acc.: 40.00%] [G loss: 0.474603]\n",
      "920 [D loss: 0.466169, acc.: 50.00%] [G loss: 0.676834]\n",
      "930 [D loss: 0.533723, acc.: 50.00%] [G loss: 0.520876]\n",
      "940 [D loss: 0.468580, acc.: 35.00%] [G loss: 0.449960]\n",
      "950 [D loss: 0.855908, acc.: 45.00%] [G loss: 0.683608]\n",
      "960 [D loss: 0.585081, acc.: 40.00%] [G loss: 0.270131]\n",
      "970 [D loss: 0.572728, acc.: 45.00%] [G loss: 0.428218]\n",
      "980 [D loss: 0.502037, acc.: 70.00%] [G loss: 0.286467]\n",
      "990 [D loss: 0.816840, acc.: 35.00%] [G loss: 0.288097]\n"
     ]
    }
   ],
   "source": [
    "gan.train(epochs=1000, batch_size=10, sample_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.load_weights('generator_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (N, 100))\n",
    "results = gan.generator.predict(noise, batch_size=10)\n",
    "#results = results*samples_std+samples_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrows,ncols=1,1\n",
    "fig = py.figure(figsize=(ncols*7,nrows*6))\n",
    "ax=py.subplot(nrows,ncols,1)\n",
    "ax.hist(norm_samples[:,0],histtype='step');\n",
    "ax.hist(results[:,0],histtype='step');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7ff1dfd82ee0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrows,ncols=1,1\n",
    "fig = py.figure(figsize=(ncols*7,nrows*6))\n",
    "IDX=range(samples.shape[1])\n",
    "Y1,dY1=[],[]\n",
    "Y2,dY2=[],[]\n",
    "for idx in IDX:\n",
    "    Y1.append(np.mean(norm_samples[:,idx]))\n",
    "    dY1.append(np.std(norm_samples[:,idx]))\n",
    "    Y2.append(np.mean(results[:,idx]))\n",
    "    dY2.append(np.std(results[:,idx]))\n",
    "ax=py.subplot(nrows,ncols,1)\n",
    "ax.errorbar(IDX,Y2,dY2,fmt='r.');    \n",
    "ax.axhline( 1,color='k',ls=':')    \n",
    "ax.axhline(-1,color='k',ls=':')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_priors=results*samples_std+samples_mean\n",
    "np.save('gan_priors.npy',optimized_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/w/jam-sciwork18/nsato/codes/pargan'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--save samples\n",
    "replica=replicas[0] #--template replica\n",
    "for i in range(N):\n",
    "    replica['params'][istep]=optimized_priors[i]\n",
    "    fname='%s/msr-opt-priors/%s.msr'%(wdir,id_generator(12))\n",
    "    save(replica,fname)\n",
    "\n",
    "print \n",
    "print('Saving new priors to %s/msr-opt-priors'%wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
